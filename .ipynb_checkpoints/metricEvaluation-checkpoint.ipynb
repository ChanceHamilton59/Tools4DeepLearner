{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.io import loadmat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Sep 24 15:11:33 2018\n",
    "\n",
    "@author: cdimattina\n",
    "\n",
    "compLinAutoEncoder.py: Compressive linear auto-encoder for 8x8 image patches\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# import modules\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.io import loadmat \n",
    "\n",
    "# simulation meta-parameters\n",
    "wscale      = 0.01; # scale of the small random weights for model initialization\n",
    "learn_rate  = 0.1;\n",
    "batchSz     = 1000;\n",
    "nEpochs     = 1000;\n",
    "fracTrain   = 0.8;\n",
    "\n",
    "beta        = 0.5; # hyper-parameter which determines penality size \n",
    "\n",
    "# define list of training data filenames \n",
    "trainDir            = 'TrainingData'\n",
    "TrainingDataFiles   = []\n",
    "\n",
    "for r, d, f in os.walk(trainDir):\n",
    "    for file in f:\n",
    "        TrainingDataFiles.append(os.path.join(r,file))\n",
    "        \n",
    "# load files and put them into a matrix\n",
    "tdata = loadmat(TrainingDataFiles[0])['X']          \n",
    "for i in range(1,len(TrainingDataFiles)):            \n",
    "    td      = loadmat(TrainingDataFiles[0])['X']\n",
    "    tdata   = np.concatenate((tdata,td), axis = 1)\n",
    "\n",
    "# put observations in rows\n",
    "tdata   = tdata.transpose()\n",
    "\n",
    "# get total number of stimuli\n",
    "nIn     = tdata.shape[1]\n",
    "nStim   = tdata.shape[0]\n",
    "nTrain  = round(fracTrain*nStim)\n",
    "\n",
    "# we compress the images by a factor of 4\n",
    "nHid  = nIn   \n",
    "\n",
    "print(\"Training Set Size   : \" + str(nTrain))\n",
    "print(\"Stimulus Dimensions : \" + str(nIn))\n",
    "print(\"Hidden Layer        : \" + str(nHid))\n",
    "\n",
    "\"\"\"\n",
    "This part of the code uses Tensorflow(R) to set up our definitions for \n",
    "the neural network. The neural network will be comprised of a single linear\n",
    "hidden layer which compresses the input image down to nHid dimensions\n",
    "\"\"\"\n",
    "\n",
    "W1mat               = tf.random_normal([nIn,nHid], mean=0.0, stddev=wscale, dtype=tf.float32, name = 'W1mat')\n",
    "\n",
    "# define tf variables and initial values for hidden layer, output layer\n",
    "hidden_layer_vals   = {'weights':tf.Variable(W1mat)}\n",
    "output_layer_vals   = {'weights':tf.Variable(tf.transpose(W1mat))}\n",
    "\n",
    "# input layer is simply a placeholder \n",
    "input_layer         = tf.placeholder('float',[None, nIn])\n",
    "hidden_layer        = tf.contrib.layers.fully_connected(tf.matmul(input_layer,hidden_layer_vals['weights']), nHid, activation_fn=None )  # linear gain\n",
    "y_pred              = tf.matmul(hidden_layer,output_layer_vals['weights'])    # multiply by transpose\n",
    "y_true              = tf.placeholder('float',[None, nIn])\n",
    "\n",
    "# define our cost function\n",
    "meansq              = tf.reduce_mean(tf.square(y_pred-y_true)) \n",
    "hiddenpenalty       = tf.reduce_mean(tf.abs(hidden_layer))\n",
    "\n",
    "penalizedmeansq     = meansq + beta*hiddenpenalty\n",
    "\n",
    "# define which optimizer we are using\n",
    "optimizer           = tf.train.AdagradOptimizer(learn_rate).minimize(penalizedmeansq)\n",
    "\n",
    "# intialize saver\n",
    "saver               = tf.train.Saver()\n",
    "\n",
    "# intialize tensorflow session\n",
    "init                = tf.global_variables_initializer()\n",
    "sess                = tf.Session() \n",
    "sess.run(init)\n",
    "\n",
    "## go through the set\n",
    "for epoch in range(nEpochs):\n",
    "    epoch_loss = 0\n",
    "    for i in range(int(nTrain/batchSz)):\n",
    "        epoch_x = tdata[i*batchSz:(i+1)*batchSz]\n",
    "        _, c    = sess.run([optimizer,penalizedmeansq], feed_dict={input_layer: epoch_x, y_true: epoch_x}) \n",
    "        epoch_loss +=c\n",
    "   \n",
    "    print('Epoch',epoch + 1, '/', nEpochs, '-- loss:',epoch_loss)\n",
    "    \n",
    "\n",
    "save_path = saver.save(sess,\"./sparseLinTrainFinal.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
